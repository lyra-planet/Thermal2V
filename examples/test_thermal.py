#!/usr/bin/env python
# coding: utf-8
"""
å¯¹æ¯”å®éªŒï¼šæ‰¾åˆ°æœ€ä¼˜çš„ç”Ÿæˆå‚æ•°ç»„åˆï¼ˆDEBUG VERSIONï¼‰
"""

import time
import os
import sys
import json
import numpy as np
import pandas as pd
from PIL import Image
from tqdm import tqdm
import torch
import pyiqa
from torchvision import transforms
import tempfile
import shutil

# ============================================================
# =============== è·¯å¾„ä¸ç¯å¢ƒé…ç½® ==============================
# ============================================================

ROOT = "/home/cunjian/kai/cache/T2V"
RUN_DIR = "/home/cunjian/kai/cache/runs/20251103-133606/ckpt/16000"
RESULTS_DIR = f"{ROOT}/output/test_thermal/results_mogle_gate_1.0"
PYTHON_PACKAGES = "/mnt/sda/python_packages"
ADAPTER_NAME = "ir_16000"

PROJECT_ROOT = f"{ROOT}/OminiControl"
CONFIG_PATH = f"{PROJECT_ROOT}/spatial_alignment_thermal.yaml"
FLUX_PATH = f"{ROOT}/requirements/FLUX.1-dev"
LORA_WEIGHT_PATH = f"{RUN_DIR}/default.safetensors"
MOGLE_WEIGHT_PATH = f"{RUN_DIR}/mogle.pt"
os.makedirs(RESULTS_DIR, exist_ok=True)

# ============================================================
# =============== æ¨¡å‹ä¸ä¾èµ–åˆå§‹åŒ– ============================
# ============================================================

os.chdir("..")
sys.path.insert(0, PYTHON_PACKAGES)
sys.path.insert(0, PROJECT_ROOT)

from omini.pipeline.flux_omini import Condition, generate, seed_everything
from omini.train_flux.trainer_t2v import get_config
from diffusers.pipelines import FluxPipeline

config = get_config(CONFIG_PATH)
training_config = config["train"]
DATA_ROOT = training_config["dataset"]["root"]
torch.cuda.empty_cache()
torch.set_float32_matmul_precision('high')
TESTA_DIR = f"{DATA_ROOT}/testA"
TESTB_DIR = f"{DATA_ROOT}/testB"
PROMPT_JSON = f"{DATA_ROOT}/test_descriptions.json"

print(f"TESTA_DIR: {TESTA_DIR}")
print(f"TESTB_DIR: {TESTB_DIR}")
print(f"PROMPT_JSON: {PROMPT_JSON}")
print("=" * 60)
print("åˆå§‹åŒ–æ¨¡å‹")
print("=" * 60)

pipe = FluxPipeline.from_pretrained(
    config["flux_path"],
    dtype=torch.bfloat16,
    device_map="balanced",
    use_auth_token=True
)

pipe.load_lora_weights(LORA_WEIGHT_PATH, adapter_name=ADAPTER_NAME, device="cuda:0")
pipe.set_adapters([ADAPTER_NAME])

import torch._dynamo
torch._dynamo.config.suppress_errors = True
torch._dynamo.config.verbose = False
pipe.transformer = torch.compile(pipe.transformer, mode="reduce-overhead")
pipe.vae.decoder = torch.compile(pipe.vae.decoder, mode="reduce-overhead")

from omini.moe.mogle_t2v_unet import MoGLE
print("âœ“ æ¨¡å‹åŠ è½½å®Œæˆ")

mogle = MoGLE()
moe_weight = torch.load(MOGLE_WEIGHT_PATH, map_location="cpu")
mogle.load_state_dict(moe_weight, strict=True)
mogle = mogle.to(device="cuda:0", dtype=torch.bfloat16)
mogle.eval()

# ============================================================
# =============== åˆå§‹åŒ– PyIQA æŒ‡æ ‡ ==========================
# ============================================================

print("\nåˆå§‹åŒ– PyIQA æŒ‡æ ‡...")
device = 'cuda:0' if torch.cuda.is_available() else 'cpu'
metric_psnr = pyiqa.create_metric('psnr', device=device)
metric_ssim = pyiqa.create_metric('ssim', device=device)
metric_lpips = pyiqa.create_metric('lpips', device=device)
metric_fid = pyiqa.create_metric('fid', device=device)
print("âœ“ PyIQA æ¨¡å‹åŠ è½½å®Œæˆ")

# ============================================================
# =============== è¯»å–æ•°æ®ä¸é…ç½® =============================
# ============================================================

# è¯»å– prompt JSON
with open(PROMPT_JSON, "r") as f:
    prompt_map = json.load(f)

print(f"âœ“ Prompt JSON å·²åŠ è½½ï¼ŒåŒ…å« {len(prompt_map)} ä¸ªæ ·æœ¬")

# å‚æ•°æœç´¢è¡¨
param_configs = [
    {"steps": 28, "guidance": 0.5, "image_guidance": 1.0, "lora_weight": 1.0, "name": "guidance_0.5"},
    {"steps": 28, "guidance": 0.7, "image_guidance": 1.0, "lora_weight": 1.0, "name": "guidance_0.7"},
    {"steps": 28, "guidance": 1.0, "image_guidance": 1.0, "lora_weight": 1.0, "name": "guidance_1.0"},
    {"steps": 28, "guidance": 1.2, "image_guidance": 1.0, "lora_weight": 1.0, "name": "guidance_1.2"},
    {"steps": 28, "guidance": 1.5, "image_guidance": 1.0, "lora_weight": 1.0, "name": "guidance_1.5_baseline"},
    {"steps": 28, "guidance": 1.8, "image_guidance": 1.0, "lora_weight": 1.0, "name": "guidance_1.8"},
    {"steps": 28, "guidance": 2.0, "image_guidance": 1.0, "lora_weight": 1.0, "name": "guidance_2.0"},
    {"steps": 28, "guidance": 2.5, "image_guidance": 1.0, "lora_weight": 1.0, "name": "guidance_2.5"},
    {"steps": 28, "guidance": 3.0, "image_guidance": 1.0, "lora_weight": 1.0, "name": "guidance_3.0"},
    {"steps": 28, "guidance": 3.5, "image_guidance": 3.5, "lora_weight": 1.0, "name": "guidance_3.5"},
]

# é€‰æ‹©éªŒè¯é›†æ–‡ä»¶
files = sorted(os.listdir(TESTA_DIR))
files = [f for f in files if f.lower().endswith((".png", ".jpg", ".jpeg"))]
print(f"âœ“ TESTA_DIR ä¸­æ‰¾åˆ° {len(files)} å¼ å›¾ç‰‡")

num_val = 2
if len(files) > num_val:
    indices = np.linspace(0, len(files) - 1, num_val, dtype=int)
    val_files = [files[i] for i in indices]
else:
    val_files = files

print(f"âœ“ ä½¿ç”¨ {len(val_files)} å¼ å›¾ç‰‡è¿›è¡ŒéªŒè¯")
print("=" * 60)

# å›¾åƒé¢„å¤„ç†
to_tensor = transforms.ToTensor()
def preprocess_image(img_path, target_size=256):
    img = Image.open(img_path).convert('RGB')
    img = img.resize((target_size, target_size), Image.Resampling.LANCZOS)
    return to_tensor(img).unsqueeze(0)

# ============================================================
# =============== å®éªŒä¸»å¾ªç¯ ================================
# ============================================================

all_results = []

for config_item in param_configs:
    config_name = config_item["name"]
    print(f"\n[{len(all_results)+1}/{len(param_configs)}] æµ‹è¯•é…ç½®: {config_name}")
    print(f"  å‚æ•°: steps={config_item['steps']}, guidance={config_item['guidance']}, "
          f"image_guidance={config_item['image_guidance']}, lora_weight={config_item['lora_weight']}")

    config_output_dir = os.path.join(RESULTS_DIR, config_name)
    os.makedirs(config_output_dir, exist_ok=True)

    psnr_scores, ssim_scores, lpips_scores = [], [], []
    config_results, success_count = [], 0
    skip_count = 0

    for filename in tqdm(val_files, desc=f"  å¤„ç†ä¸­", ncols=60):
        try:
            # ğŸ”§ prompt_map çš„ key åŒ…å«æ‰©å±•åï¼Œæ‰€ä»¥ç›´æ¥ç”¨ filename ä½œä¸º key
            key = filename
            if key not in prompt_map:
                skip_count += 1
                continue
            prompt = prompt_map[key]
            if not isinstance(prompt, str):
                skip_count += 1
                continue

            src_path = os.path.join(TESTA_DIR, filename)
            tgt_path = os.path.join(TESTB_DIR, filename)
            if not (os.path.exists(src_path) and os.path.exists(tgt_path)):
                skip_count += 1
                continue

            image = Image.open(src_path).convert("RGB").resize((256, 256))
            target_image = Image.open(tgt_path).convert("RGB").resize((256, 256))

            condition = Condition(image, ADAPTER_NAME)
            seed_everything()
            result_img = generate(
                pipe,
                prompt=prompt,
                conditions=[condition],
                height=256,
                width=256,
                num_inference_steps=config_item["steps"],
                guidance_scale=config_item["guidance"],
                image_guidance_scale=config_item["image_guidance"],
                mogle=mogle,
                use_mogle=True
            ).images[0]

            result_tensor = to_tensor(result_img).unsqueeze(0).to(device)
            target_tensor = to_tensor(target_image).unsqueeze(0).to(device)

            with torch.no_grad():
                psnr = metric_psnr(result_tensor, target_tensor).item()
                ssim = metric_ssim(result_tensor, target_tensor).item()
                lpips = metric_lpips(result_tensor, target_tensor).item()

            psnr_scores.append(psnr)
            ssim_scores.append(ssim)
            lpips_scores.append(lpips)
            success_count += 1

            config_results.append({"filename": filename, "PSNR": psnr, "SSIM": ssim, "LPIPS": lpips})

            compare = Image.new('RGB', (512, 256))
            compare.paste(target_image, (0, 0))
            compare.paste(result_img, (256, 0))
            compare.save(os.path.join(config_output_dir,
                        f"{os.path.splitext(filename)[0]}_P{psnr:.2f}_S{ssim:.4f}_L{lpips:.4f}.png"))

        except Exception as e:
            print(f"    âŒ é”™è¯¯: {filename}: {e}")
            continue

    print(f"    è·³è¿‡: {skip_count}, æˆåŠŸ: {success_count}/{len(val_files)}")

    # è®¡ç®—ç»Ÿè®¡æŒ‡æ ‡
    if psnr_scores:
        avg_psnr, avg_ssim, avg_lpips = np.mean(psnr_scores), np.mean(ssim_scores), np.mean(lpips_scores)
        std_psnr, std_ssim, std_lpips = np.std(psnr_scores), np.std(ssim_scores), np.std(lpips_scores)

        print("  è®¡ç®— FID...")
        with tempfile.TemporaryDirectory() as tmpdir:
            tmp_gen, tmp_ref = os.path.join(tmpdir, "gen"), os.path.join(tmpdir, "ref")
            os.makedirs(tmp_gen, exist_ok=True)
            os.makedirs(tmp_ref, exist_ok=True)

            for res in config_results:
                gen = Image.open(os.path.join(TESTA_DIR, res["filename"])).convert('RGB').resize((256, 256))
                ref = Image.open(os.path.join(TESTB_DIR, res["filename"])).convert('RGB').resize((256, 256))
                gen.save(os.path.join(tmp_gen, res["filename"]))
                ref.save(os.path.join(tmp_ref, res["filename"]))

            fid_score = metric_fid(tmp_gen, tmp_ref).item()

        result_entry = {
            "config": config_name,
            "params": config_item,
            "psnr": {"mean": float(avg_psnr), "std": float(std_psnr)},
            "ssim": {"mean": float(avg_ssim), "std": float(std_ssim)},
            "lpips": {"mean": float(avg_lpips), "std": float(std_lpips)},
            "fid": float(fid_score),
            "success_count": success_count
        }
        all_results.append(result_entry)

        df = pd.DataFrame(config_results)
        df.loc[len(df)] = {"filename": "Average", "PSNR": avg_psnr, "SSIM": avg_ssim, "LPIPS": avg_lpips}
        df.to_csv(os.path.join(config_output_dir, "metrics.csv"), index=False)

        print(f"  âœ“ PSNR: {avg_psnr:.4f} | SSIM: {avg_ssim:.4f} | LPIPS: {avg_lpips:.4f} | FID: {fid_score:.4f}")
    else:
        print("  âŒ æ— æœ‰æ•ˆç»“æœ")

# ============================================================
# =============== ç»“æœæ€»ç»“ä¸æ¨è =============================
# ============================================================

print("\n" + "=" * 60)
print("å®éªŒç»“æœæ€»ç»“")
print("=" * 60)

# âš ï¸ æ·»åŠ ç©ºæ£€æŸ¥
if not all_results:
    print("âŒ é”™è¯¯ï¼šæ²¡æœ‰æˆåŠŸå¤„ç†ä»»ä½•é…ç½®ï¼")
    print("å¯èƒ½åŸå› ï¼š")
    print("  1. prompt_map ä¸ºç©ºæˆ– JSON æ–‡ä»¶ä¸å­˜åœ¨")
    print("  2. testA/testB ç›®å½•ä¸å­˜åœ¨æˆ–ä¸ºç©º")
    print("  3. æ–‡ä»¶åä¸åŒ¹é… (key not in prompt_map)")
    print("  4. å›¾åƒæ–‡ä»¶æŸå")
    sys.exit(1)

results_by_psnr = sorted(all_results, key=lambda x: x["psnr"]["mean"], reverse=True)
results_by_ssim = sorted(all_results, key=lambda x: x["ssim"]["mean"], reverse=True)
results_by_lpips = sorted(all_results, key=lambda x: x["lpips"]["mean"])
results_by_fid = sorted(all_results, key=lambda x: x["fid"])

output_file = os.path.join(RESULTS_DIR, "tune_results.json")
with open(output_file, "w") as f:
    json.dump(all_results, f, indent=2)

print(f"\nâœ“ ç»“æœå·²ä¿å­˜åˆ°: {output_file}")

def print_top(title, arr, key, reverse=True):
    print(f"\nã€æŒ‰ {title} æ’åºã€‘")
    for i, r in enumerate(arr, 1):
        val = r[key]['mean'] if isinstance(r[key], dict) else r[key]
        print(f"{i}. {r['config']:25s} {key}: {val:.4f}")

print_top("PSNRï¼ˆè¶Šé«˜è¶Šå¥½ï¼‰", results_by_psnr, "psnr")
print_top("SSIMï¼ˆè¶Šé«˜è¶Šå¥½ï¼‰", results_by_ssim, "ssim")
print_top("LPIPSï¼ˆè¶Šä½è¶Šå¥½ï¼‰", results_by_lpips, "lpips", reverse=False)
print_top("FIDï¼ˆè¶Šä½è¶Šå¥½ï¼‰", results_by_fid, "fid", reverse=False)

# æ¨èé…ç½®
best_lpips, best_psnr, best_ssim, best_fid = results_by_lpips[0], results_by_psnr[0], results_by_ssim[0], results_by_fid[0]

print(f"\n{'='*60}\næ¨èé…ç½®\n{'='*60}")
print(f"\næœ€ä½³ LPIPS: {best_lpips['config']}  LPIPS={best_lpips['lpips']['mean']:.4f}")
print(f"æœ€ä½³ PSNR:  {best_psnr['config']}  PSNR={best_psnr['psnr']['mean']:.4f}")
print(f"æœ€ä½³ SSIM:  {best_ssim['config']}  SSIM={best_ssim['ssim']['mean']:.4f}")
print(f"æœ€ä½³ FID:   {best_fid['config']}   FID={best_fid['fid']:.4f}")

print(f"\nã€ç»¼åˆæ¨èã€‘å»ºè®®ä½¿ç”¨ {best_lpips['config']} çš„å‚æ•°ï¼š")
print(f"  num_inference_steps={best_lpips['params']['steps']},")
print(f"  guidance_scale={best_lpips['params']['guidance']},")
print(f"  image_guidance_scale={best_lpips['params']['image_guidance']}")
if best_lpips['params']['lora_weight'] != 1.0:
    print(f"  adapter_weights=[{best_lpips['params']['lora_weight']}]")
print(f"{'='*60}")