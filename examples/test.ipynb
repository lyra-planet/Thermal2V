{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a28972c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pyiqa\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "import glob\n",
    "import os\n",
    "import pandas as pd\n",
    "import tempfile\n",
    "from tqdm import tqdm\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "895f32b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… å‘ç° 2 å¯¹åŒ¹é…å›¾ç‰‡\n",
      "ğŸ“ çœŸå®å›¾åƒæ–‡ä»¶å¤¹: /home/cunjian/kai/cache/T2V/t2v_dataset/testB\n",
      "ğŸ“ ç”Ÿæˆå›¾åƒæ–‡ä»¶å¤¹: /home/cunjian/kai/cache/T2V/output/gen_result/results_mogle_gate_1.0/result\n",
      "\n",
      "ğŸ”§ ä½¿ç”¨è®¾å¤‡: cuda\n",
      "\n",
      "Loading pretrained model LPIPS from /home/cunjian/.cache/torch/hub/pyiqa/LPIPS_v0.1_alex-df73285e.pth\n",
      "Loading pretrained model Inception3 from /home/cunjian/.cache/torch/hub/pyiqa/pt_inception-2015-12-05-6726825d.pth\n",
      "ğŸ“Š å¼€å§‹è®¡ç®— PSNR/SSIM/LPIPS...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 58.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“Š å¼€å§‹è®¡ç®— FID...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying images for FID: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 10.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing FID between two folders\n",
      "Found 2 images in the folder /tmp/tmp76dtcb3j/test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "FID test: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  3.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2 images in the folder /tmp/tmp76dtcb3j/ref\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "FID ref: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  3.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "âœ… è®¡ç®—å®Œæˆï¼\n",
      "============================================================\n",
      "ğŸ“Š é€å›¾æŒ‡æ ‡å·²ä¿å­˜åˆ°: /home/cunjian/kai/cache/T2V/output/gen_result/results_mogle_gate_1.0/metric_results.csv\n",
      "\n",
      "ğŸ“ˆ å¹³å‡æŒ‡æ ‡:\n",
      "   PSNR:  22.4485 dB  (â†‘ è¶Šé«˜è¶Šå¥½) || 29.45\n",
      "   SSIM:  0.7656     (â†‘ è¶Šé«˜è¶Šå¥½, æœ€ä½³=1) || 0.7504\n",
      "   LPIPS: 0.1416     (â†“ è¶Šä½è¶Šå¥½) || 0.1650\n",
      "   FID:   70.3302     (â†“ è¶Šä½è¶Šå¥½) || 34.02\n",
      "============================================================\n",
      "\n",
      "ğŸ“¸ å¼€å§‹ä¿å­˜å¯¹æ¯”å›¾ç‰‡...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving comparison images: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  9.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… å¯¹æ¯”å›¾ç‰‡å·²ä¿å­˜åˆ°: /home/cunjian/kai/cache/T2V/output/gen_result/results_mogle_gate_1.0/comparison\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# -------------------------\n",
    "# æ–‡ä»¶å¤¹è·¯å¾„\n",
    "# -------------------------\n",
    "load_dotenv(\"../.env\")\n",
    "ROOT = os.getenv(\"ROOT\")\n",
    "print(\"ROOT:\", ROOT)\n",
    "RESULTS_DIR = f\"{ROOT}/output/gen_result/results_mogle_gate_1.0\"\n",
    "test_dir = f\"{RESULTS_DIR}/result\"\n",
    "ref_dir = f\"{ROOT}/t2v_dataset/testB\"  # çœŸå®å›¾åƒï¼ˆground truthï¼‰\n",
    "# -------------------------\n",
    "# è·å–å›¾ç‰‡\n",
    "# -------------------------\n",
    "ref_imgs = glob.glob(os.path.join(ref_dir, \"*.png\"))\n",
    "test_imgs = glob.glob(os.path.join(test_dir, \"*.png\"))\n",
    "\n",
    "ref_dict = {os.path.basename(p): p for p in ref_imgs}\n",
    "test_dict = {os.path.basename(p): p for p in test_imgs}\n",
    "\n",
    "common_names = sorted(set(ref_dict.keys()) & set(test_dict.keys()))\n",
    "\n",
    "if not common_names:\n",
    "    raise ValueError(\"ä¸¤ä¸ªæ–‡ä»¶å¤¹æ²¡æœ‰ä»»ä½•åŒåå›¾ç‰‡ï¼Œè¯·æ£€æŸ¥å‘½åï¼\")\n",
    "\n",
    "print(f\"âœ… å‘ç° {len(common_names)} å¯¹åŒ¹é…å›¾ç‰‡\")\n",
    "print(f\"ğŸ“ çœŸå®å›¾åƒæ–‡ä»¶å¤¹: {ref_dir}\")\n",
    "print(f\"ğŸ“ ç”Ÿæˆå›¾åƒæ–‡ä»¶å¤¹: {test_dir}\\n\")\n",
    "\n",
    "# -------------------------\n",
    "# åˆ›å»ºæŒ‡æ ‡\n",
    "# -------------------------\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f\"ğŸ”§ ä½¿ç”¨è®¾å¤‡: {device}\\n\")\n",
    "\n",
    "metric_psnr = pyiqa.create_metric('psnr', device=device)\n",
    "metric_ssim = pyiqa.create_metric('ssim', device=device)\n",
    "metric_lpips = pyiqa.create_metric('lpips', device=device)\n",
    "metric_fid = pyiqa.create_metric('fid', device=device)\n",
    "\n",
    "to_tensor = transforms.ToTensor()\n",
    "results = []\n",
    "\n",
    "# -------------------------\n",
    "# å®šä¹‰ç»Ÿä¸€çš„å›¾åƒé¢„å¤„ç†å‡½æ•°ï¼ˆç›´æ¥resizeï¼‰\n",
    "# -------------------------\n",
    "def preprocess_image(img_path, target_size=256):\n",
    "    \"\"\"\n",
    "    ç»Ÿä¸€çš„å›¾åƒé¢„å¤„ç†ï¼šç›´æ¥resize â†’ è½¬tensor\n",
    "    ï¼ˆä¸è®­ç»ƒè„šæœ¬ä¿æŒä¸€è‡´ï¼‰\n",
    "    \"\"\"\n",
    "    img = Image.open(img_path).convert('RGB')\n",
    "    \n",
    "    # ç›´æ¥resizeåˆ°å›ºå®šå°ºå¯¸\n",
    "    img = img.resize((target_size, target_size), Image.Resampling.LANCZOS)\n",
    "    \n",
    "    # è½¬tensorï¼Œå€¼åŸŸ [0, 1]\n",
    "    tensor = to_tensor(img)  # è‡ªåŠ¨è½¬ä¸º [0, 1]\n",
    "    \n",
    "    return tensor.unsqueeze(0)\n",
    "\n",
    "# -------------------------\n",
    "# PSNR / SSIM / LPIPS é€å¯¹è®¡ç®—\n",
    "# -------------------------\n",
    "print(\"ğŸ“Š å¼€å§‹è®¡ç®— PSNR/SSIM/LPIPS...\")\n",
    "with torch.no_grad():\n",
    "    for i, name in enumerate(tqdm(common_names, desc=\"Processing images\")):\n",
    "        ref_path = ref_dict[name]\n",
    "        test_path = test_dict[name]\n",
    "        \n",
    "        # ç»Ÿä¸€é¢„å¤„ç†ä¸¤ä¸ªå›¾åƒ\n",
    "        ref_tensor = preprocess_image(ref_path).to(device)\n",
    "        test_tensor = preprocess_image(test_path).to(device)\n",
    "        \n",
    "        # è®¡ç®—æŒ‡æ ‡ï¼ˆç”Ÿæˆå›¾åƒ vs çœŸå®å›¾åƒï¼‰\n",
    "        psnr = metric_psnr(test_tensor, ref_tensor).item()\n",
    "        ssim = metric_ssim(test_tensor, ref_tensor).item()\n",
    "        lpips = metric_lpips(test_tensor, ref_tensor).item()\n",
    "        \n",
    "        results.append({\n",
    "            \"filename\": name,\n",
    "            \"PSNR\": psnr,\n",
    "            \"SSIM\": ssim,\n",
    "            \"LPIPS\": lpips,\n",
    "        })\n",
    "        \n",
    "        # åŠæ—¶æ¸…ç†ä¸­é—´å˜é‡å’Œæ˜¾å­˜\n",
    "        del ref_tensor, test_tensor\n",
    "        if (i + 1) % 100 == 0:\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "# -------------------------\n",
    "# æ‰¹é‡è®¡ç®— FIDï¼ˆä»…é’ˆå¯¹åŒ¹é…å›¾ç‰‡ï¼‰\n",
    "# -------------------------\n",
    "print(\"\\nğŸ“Š å¼€å§‹è®¡ç®— FID...\")\n",
    "with tempfile.TemporaryDirectory() as tmpdir:\n",
    "    tmp_ref = os.path.join(tmpdir, \"ref\")\n",
    "    tmp_test = os.path.join(tmpdir, \"test\")\n",
    "    os.makedirs(tmp_ref, exist_ok=True)\n",
    "    os.makedirs(tmp_test, exist_ok=True)\n",
    "    \n",
    "    # å¤åˆ¶å¹¶å¤„ç†åŒ¹é…çš„å›¾ç‰‡åˆ°ä¸´æ—¶æ–‡ä»¶å¤¹\n",
    "    for name in tqdm(common_names, desc=\"Copying images for FID\"):\n",
    "        ref_img = Image.open(ref_dict[name]).convert('RGB')\n",
    "        test_img = Image.open(test_dict[name]).convert('RGB')\n",
    "        \n",
    "        # ç›´æ¥resizeå¤„ç†ï¼ˆä¸è®­ç»ƒè„šæœ¬ä¿æŒä¸€è‡´ï¼‰\n",
    "        ref_img = ref_img.resize((256, 256), Image.Resampling.LANCZOS)\n",
    "        test_img = test_img.resize((256, 256), Image.Resampling.LANCZOS)\n",
    "        \n",
    "        ref_img.save(os.path.join(tmp_ref, name))\n",
    "        test_img.save(os.path.join(tmp_test, name))\n",
    "    \n",
    "    # è®¡ç®— FIDï¼ˆç”Ÿæˆå›¾åƒæ–‡ä»¶å¤¹ vs çœŸå®å›¾åƒæ–‡ä»¶å¤¹ï¼‰\n",
    "    fid_value = metric_fid(tmp_test, tmp_ref).item()\n",
    "\n",
    "# -------------------------\n",
    "# ä¿å­˜ç»“æœ\n",
    "# -------------------------\n",
    "df = pd.DataFrame(results)\n",
    "\n",
    "# æ·»åŠ å¹³å‡å€¼è¡Œ\n",
    "avg_row = {\n",
    "    'filename': 'Average',\n",
    "    'PSNR': df['PSNR'].mean(),\n",
    "    'SSIM': df['SSIM'].mean(),\n",
    "    'LPIPS': df['LPIPS'].mean(),\n",
    "}\n",
    "df = pd.concat([df, pd.DataFrame([avg_row])], ignore_index=True)\n",
    "\n",
    "# ä¿å­˜ CSV\n",
    "csv_path = RESULTS_DIR+\"/metric_results.csv\"\n",
    "df.to_csv(csv_path, index=False)\n",
    "\n",
    "\n",
    "# -------------------------\n",
    "# æ‰“å°ç»“æœæ‘˜è¦\n",
    "# -------------------------\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"âœ… è®¡ç®—å®Œæˆï¼\")\n",
    "print(\"=\"*60)\n",
    "print(f\"ğŸ“Š é€å›¾æŒ‡æ ‡å·²ä¿å­˜åˆ°: {csv_path}\")\n",
    "print(f\"\\nğŸ“ˆ å¹³å‡æŒ‡æ ‡:\")\n",
    "print(f\"   PSNR:  {avg_row['PSNR']:.4f} dB  (â†‘ è¶Šé«˜è¶Šå¥½) || 29.45\")\n",
    "print(f\"   SSIM:  {avg_row['SSIM']:.4f}     (â†‘ è¶Šé«˜è¶Šå¥½, æœ€ä½³=1) || 0.7504\")\n",
    "print(f\"   LPIPS: {avg_row['LPIPS']:.4f}     (â†“ è¶Šä½è¶Šå¥½) || 0.1650\")\n",
    "print(f\"   FID:   {fid_value:.4f}     (â†“ è¶Šä½è¶Šå¥½) || 34.02\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# -------------------------\n",
    "# ä¿å­˜å¯¹æ¯”å›¾ç‰‡åˆ°æ–‡ä»¶å¤¹\n",
    "# -------------------------\n",
    "print(\"\\nğŸ“¸ å¼€å§‹ä¿å­˜å¯¹æ¯”å›¾ç‰‡...\")\n",
    "output_compare_dir = RESULTS_DIR+\"/comparison\"\n",
    "\n",
    "# æ¸…ç©ºè¾“å‡ºæ–‡ä»¶å¤¹\n",
    "if os.path.exists(output_compare_dir):\n",
    "    import shutil\n",
    "    shutil.rmtree(output_compare_dir)\n",
    "    print(f\"âœ“ å·²æ¸…ç©ºåŸæœ‰çš„ {output_compare_dir} æ–‡ä»¶å¤¹\")\n",
    "\n",
    "os.makedirs(output_compare_dir, exist_ok=True)\n",
    "\n",
    "for name in tqdm(common_names, desc=\"Saving comparison images\"):\n",
    "    ref_path = ref_dict[name]\n",
    "    test_path = test_dict[name]\n",
    "    \n",
    "    ref_img = Image.open(ref_path).convert('RGB')\n",
    "    test_img = Image.open(test_path).convert('RGB')\n",
    "    \n",
    "    # ç›´æ¥resizeå¤„ç†\n",
    "    ref_img = ref_img.resize((256, 256))\n",
    "    test_img = test_img.resize((256, 256))\n",
    "    \n",
    "    # åˆ›å»ºå¯¹æ¯”å›¾ (çœŸå® | ç”Ÿæˆ)\n",
    "    compare_img = Image.new('RGB', (512, 256))\n",
    "    compare_img.paste(ref_img, (0, 0))\n",
    "    compare_img.paste(test_img, (256, 0))\n",
    "    \n",
    "    # è·å–å¯¹åº”çš„æŒ‡æ ‡\n",
    "    row = df[df['filename'] == name].iloc[0]\n",
    "    psnr = row['PSNR']\n",
    "    ssim = row['SSIM']\n",
    "    lpips = row['LPIPS']\n",
    "    \n",
    "    # ä¿å­˜æ–‡ä»¶ååŒ…å«æŒ‡æ ‡ä¿¡æ¯\n",
    "    output_name = f\"{os.path.splitext(name)[0]}_PSNR{psnr:.2f}_SSIM{ssim:.4f}_LPIPS{lpips:.4f}.png\"\n",
    "    output_path = os.path.join(output_compare_dir, output_name)\n",
    "    compare_img.save(output_path)\n",
    "\n",
    "print(f\"âœ… å¯¹æ¯”å›¾ç‰‡å·²ä¿å­˜åˆ°: {output_compare_dir}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ea05033",
   "metadata": {},
   "source": [
    "ğŸ“ˆ å¹³å‡æŒ‡æ ‡:\n",
    "   PSNR:  21.3718 dB  (â†‘ è¶Šé«˜è¶Šå¥½) || 29.45\n",
    "   SSIM:  0.7871     (â†‘ è¶Šé«˜è¶Šå¥½, æœ€ä½³=1) || 0.7504\n",
    "   LPIPS: 0.1698     (â†“ è¶Šä½è¶Šå¥½) || 0.1650\n",
    "   FID:   35.0483     (â†“ è¶Šä½è¶Šå¥½) || 34.02"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccaf0060",
   "metadata": {},
   "source": [
    "ğŸ“ˆ å¹³å‡æŒ‡æ ‡:\n",
    "   PSNR:  21.4603 dB  (â†‘ è¶Šé«˜è¶Šå¥½) || 29.45\n",
    "   SSIM:  0.7907     (â†‘ è¶Šé«˜è¶Šå¥½, æœ€ä½³=1) || 0.7504\n",
    "   LPIPS: 0.1671     (â†“ è¶Šä½è¶Šå¥½) || 0.1650\n",
    "   FID:   34.9702     (â†“ è¶Šä½è¶Šå¥½) || 34.02"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c09d8a06",
   "metadata": {},
   "source": [
    "ğŸ“ˆ å¹³å‡æŒ‡æ ‡:\n",
    "   PSNR:  21.4549 dB  (â†‘ è¶Šé«˜è¶Šå¥½) || 29.45\n",
    "   SSIM:  0.7903     (â†‘ è¶Šé«˜è¶Šå¥½, æœ€ä½³=1) || 0.7504\n",
    "   LPIPS: 0.1673     (â†“ è¶Šä½è¶Šå¥½) || 0.1650\n",
    "   FID:   34.4538     (â†“ è¶Šä½è¶Šå¥½) || 34.02"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dd2ac74",
   "metadata": {},
   "source": [
    "ğŸ“ˆ å¹³å‡æŒ‡æ ‡:\n",
    "   PSNR:  20.8287 dB  (â†‘ è¶Šé«˜è¶Šå¥½)\n",
    "   SSIM:  0.7597     (â†‘ è¶Šé«˜è¶Šå¥½, æœ€ä½³=1)\n",
    "   LPIPS: 0.2049     (â†“ è¶Šä½è¶Šå¥½)\n",
    "   FID:   36.5074     (â†“ è¶Šä½è¶Šå¥½)\n",
    "   \n",
    "ğŸ“ˆ å¹³å‡æŒ‡æ ‡:\n",
    "   PSNR:  21.5972 dB  (â†‘ è¶Šé«˜è¶Šå¥½) || 29.45\n",
    "   SSIM:  0.7862     (â†‘ è¶Šé«˜è¶Šå¥½, æœ€ä½³=1) || 0.7504\n",
    "   LPIPS: 0.1676     (â†“ è¶Šä½è¶Šå¥½) || 0.1650\n",
    "   FID:   20.3711     (â†“ è¶Šä½è¶Šå¥½) || 34.02\n",
    "============================================\n",
    "\n",
    "ğŸ“ˆ å¹³å‡æŒ‡æ ‡:\n",
    "   PSNR:  22.3148 dB  (â†‘ è¶Šé«˜è¶Šå¥½) || 29.45\n",
    "   SSIM:  0.7986     (â†‘ è¶Šé«˜è¶Šå¥½, æœ€ä½³=1) || 0.7504\n",
    "   LPIPS: 0.1616     (â†“ è¶Šä½è¶Šå¥½) || 0.1650\n",
    "   FID:   18.2953     (â†“ è¶Šä½è¶Šå¥½) || 34.02\n",
    "============================================================"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "omini",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
